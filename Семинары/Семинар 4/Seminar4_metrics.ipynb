{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оценка качества моделей классификации.\n",
    "\n",
    "Будем тренироваться интерпретировать качество моделей классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача: датасет о кредитном скоринге. \n",
    "* Колонки 0, 1, ..., 13 - анонимизированные характеристики клиентов (некоторые числовые, некоторые категориальные). \n",
    "* Target - целевая переменная: 1 - выдать кредит, 0 - не выдать кредит.\n",
    "\n",
    "На этих данных было обучено три различных алгоритма классификации и получены предсказания:\n",
    "* pred1_probs - предсказанные вероятности положительного класса, полученные алгоритмом 1.\n",
    "* pred1_classes - предсказанные алгоритмом 1 классы\n",
    "* pred2_probs, pred2_classes, pred3_probs, pred3_classes - аналогичные величины для алгоритмов 2 и 3\n",
    "\n",
    "Наша задача - оценить качество каждого из трех алгоритмов и разобраться, какой из алгоритмов лучше всего работает в данной задаче."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"credit_scoring_example1.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, сбалансированная ли выборка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.target == 0]), len(df[df.target == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим **accuracy** - долю правильных ответов каждого из алгоритмов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('алгоритм 1:', accuracy_score(df['target'], df['pred1_classes']))\n",
    "print('алгоритм 2:', accuracy_score(df['target'], df['pred2_classes']))\n",
    "print('алгоритм 3:', accuracy_score(df['target'], df['pred3_classes']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***С точки зрения метрики accuracy второй алгоритм работает немного лучше остальных***. Посмотрим на другие метрики.\n",
    "\n",
    "Теперь посмотрим на **precision** и **recall**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "print('алгоритм 1:')\n",
    "print('точность:', precision_score(df['target'], df['pred1_classes']))\n",
    "print('полнота:',  recall_score(df['target'], df['pred1_classes']))\n",
    "print('алгоритм 2:')\n",
    "print('точность:', precision_score(df['target'], df['pred2_classes']))\n",
    "print('полнота:',  recall_score(df['target'], df['pred2_classes']))\n",
    "print('алгоритм 3:')\n",
    "print('точность:', precision_score(df['target'], df['pred3_classes']))\n",
    "print('полнота:',  recall_score(df['target'], df['pred3_classes']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самым полезным инструментом в практических задачах является ***матрица ошибок***. Смотря на неё и регулируя порог, определяющий классы, мы можем достичь оптимального решения нашей задачи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    " \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    " \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    " \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('алгоритм 1')\n",
    "plot_confusion_matrix(confusion_matrix(df['target'], df['pred1_classes']), classes=['0','1'],\n",
    "                        title='Confusion matrix, without normalization')\n",
    "show()\n",
    "print('алгоритм 2')\n",
    "plot_confusion_matrix(confusion_matrix(df['target'], df['pred2_classes']), classes=['0','1'],\n",
    "                        title='Confusion matrix, without normalization')\n",
    "show()\n",
    "print('алгоритм 3')\n",
    "plot_confusion_matrix(confusion_matrix(df['target'], df['pred3_classes']), classes=['0','1'],\n",
    "                        title='Confusion matrix, without normalization')\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте определимся с целями нашего предсказания:\n",
    "    \n",
    "* **Вариант 1**: хотим выдать кредит максимальному числу людей среди тех, кто мог бы его вернуть. При этом не хотим много ошибаться (общее число ошибок не более 35%).\n",
    "  \n",
    "1) Мы не хотим, чтобы алгоритм много ошибался: accuracy $\\geq$ 0.65.\n",
    "\n",
    "2) Кроме того полнота должна быть как можно больше (число в левом нижнем квадрате матрицы ошибок минимально).\n",
    "\n",
    "Будем изменять порог вероятности в цикле и смотреть на результаты.\n",
    "\n",
    "Смотрим на **модель 1**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in np.arange(0.1,1,0.1):\n",
    "    pred1_thr = [1 if x >= t else 0 for x in df['pred1_probs']]\n",
    "    print('threshold =', t)\n",
    "    print('полнота(recall):', recall_score(df['target'],pred1_thr))\n",
    "    print('accuracy:', accuracy_score(df['target'],pred1_thr))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in np.arange(0.35,0.6,0.025):\n",
    "    pred1_thr = [1 if x >= t else 0 for x in df['pred1_probs']]\n",
    "    print('threshold =', t)\n",
    "    print('полнота(recall):', recall_score(df['target'],pred1_thr))\n",
    "    print('accuracy:', accuracy_score(df['target'],pred1_thr))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Наилучший результат:***\n",
    "\n",
    "threshold = 0.375\n",
    "\n",
    "полнота(recall): 0.71\n",
    "\n",
    "accuracy: 0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1_thr = [1 if x >= 0.375 else 0 for x in df['pred1_probs']]\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix(df['target'], pred1_thr), classes=['0','1'],\n",
    "                        title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь посмотрим на **модель 2**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in np.arange(0.1,1,0.1):\n",
    "    pred2_thr = [1 if x >= t else 0 for x in df['pred2_probs']]\n",
    "    print('threshold =', t)\n",
    "    print('полнота(recall):', recall_score(df['target'],pred2_thr))\n",
    "    print('accuracy:', accuracy_score(df['target'],pred2_thr))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for t in np.arange(0.25,0.8,0.025):\n",
    "    pred2_thr = [1 if x >= t else 0 for x in df['pred2_probs']]\n",
    "    print('threshold =', t)\n",
    "    print('полнота(recall):', recall_score(df['target'],pred2_thr))\n",
    "    print('accuracy:', accuracy_score(df['target'],pred2_thr))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Наилучший результат:***\n",
    "\n",
    "threshold = 0.3\n",
    "\n",
    "полнота(recall): 0.837\n",
    "    \n",
    "accuracy: 0.675"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2_thr = [1 if x >= 0.3 else 0 for x in df['pred2_probs']]\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix(df['target'], pred2_thr), classes=['0','1'],\n",
    "                        title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на **модель 3**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in np.arange(0.1,1,0.1):\n",
    "    pred3_thr = [1 if x >= t else 0 for x in df['pred3_probs']]\n",
    "    print('threshold =', t)\n",
    "    print('полнота(recall):', recall_score(df['target'],pred3_thr))\n",
    "    print('accuracy:', accuracy_score(df['target'],pred3_thr))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in np.arange(0.35,0.6,0.025):\n",
    "    pred3_thr = [1 if x >= t else 0 for x in df['pred3_probs']]\n",
    "    print('threshold =', t)\n",
    "    print('полнота(recall):', recall_score(df['target'],pred3_thr))\n",
    "    print('accuracy:', accuracy_score(df['target'],pred3_thr))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Наилучший результат:***\n",
    "\n",
    "threshold = 0.4\n",
    "\n",
    "полнота(recall): 0.414\n",
    "    \n",
    "accuracy: 0.646 (наибольшая точность)\n",
    "\n",
    "***Модель не проходит по критериям (точность меньше 0.65)!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred3_thr = [1 if x >= 0.4 else 0 for x in df['pred3_probs']]\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix(df['target'], pred3_thr), classes=['0','1'],\n",
    "                        title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводы:** с поставленной задачей лучше всего справляется модель 2 (полнота: 0.837,\n",
    "accuracy: 0.675). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша цель может звучать и по-другому:\n",
    "    \n",
    "* **Вариант 2**: среди тех, кому модель выдает кредит, должно быть меньше всего ошибок (мало людей, кто его на самом деле не вернет - на них будем терять деньги). \n",
    "    При этом не хотим много ошибаться (общее число ошибок не более 35%).\n",
    "  \n",
    "1) Мы не хотим, чтобы алгоритм много ошибался: accuracy $\\geq$ 0.65.\n",
    "\n",
    "2) Кроме того точность должна быть как можно больше (число в правом верхнем квадрате матрицы ошибок минимально).\n",
    "\n",
    "Будем изменять порог вероятности в цикле и смотреть на результаты.\n",
    "\n",
    "Смотрим на **модель 1**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in np.arange(0.1,1,0.1):\n",
    "    pred1_thr = [1 if x >= t else 0 for x in df['pred1_probs']]\n",
    "    print('threshold =', t)\n",
    "    print('точность(precision):', precision_score(df['target'],pred1_thr))\n",
    "    print('accuracy:', accuracy_score(df['target'],pred1_thr))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in np.arange(0.35,0.6,0.1):\n",
    "    pred1_thr = [1 if x >= t else 0 for x in df['pred1_probs']]\n",
    "    print('threshold =', t)\n",
    "    print('точность(precision):', precision_score(df['target'],pred1_thr))\n",
    "    print('accuracy:', accuracy_score(df['target'],pred1_thr))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Наилучший результат:***\n",
    "\n",
    "threshold = 0.55\n",
    "\n",
    "точность(precision): 0.733\n",
    "    \n",
    "accuracy: 0.653"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1_thr = [1 if x >= 0.55 else 0 for x in df['pred1_probs']]\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix(df['target'], pred1_thr), classes=['0','1'],\n",
    "                        title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрим на **модель 2**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in np.arange(0.1,1,0.1):\n",
    "    pred2_thr = [1 if x >= t else 0 for x in df['pred2_probs']]\n",
    "    print('threshold =', t)\n",
    "    print('точность(precision):', precision_score(df['target'],pred2_thr))\n",
    "    print('accuracy:', accuracy_score(df['target'],pred2_thr))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in np.arange(0.25,0.8,0.025):\n",
    "    pred2_thr = [1 if x >= t else 0 for x in df['pred2_probs']]\n",
    "    print('threshold =', t)\n",
    "    print('точность(precision):', precision_score(df['target'],pred2_thr))\n",
    "    print('accuracy:', accuracy_score(df['target'],pred2_thr))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Наилучший результат:***\n",
    "\n",
    "threshold = 0.725\n",
    "\n",
    "точность(precision): 0.837\n",
    "    \n",
    "accuracy: 0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2_thr = [1 if x >= 0.725 else 0 for x in df['pred2_probs']]\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix(df['target'], pred2_thr), classes=['0','1'],\n",
    "                        title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрим на **модель 3**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in np.arange(0.1,1,0.1):\n",
    "    pred3_thr = [1 if x >= t else 0 for x in df['pred3_probs']]\n",
    "    print('threshold =', t)\n",
    "    print('точность(precision):', precision_score(df['target'],pred3_thr))\n",
    "    print('accuracy:', accuracy_score(df['target'],pred3_thr))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in np.arange(0.4,0.65,0.025):\n",
    "    pred3_thr = [1 if x >= t else 0 for x in df['pred3_probs']]\n",
    "    print('threshold =', t)\n",
    "    print('точность(precision):', precision_score(df['target'],pred3_thr))\n",
    "    print('accuracy:', accuracy_score(df['target'],pred3_thr))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Наилучший результат:***\n",
    "\n",
    "threshold = 0.575\n",
    "\n",
    "точность(precision): 0.714\n",
    "    \n",
    "accuracy: 0.642\n",
    "    \n",
    "***Модель не проходит по критериям (точность меньше 0.65)!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred3_thr = [1 if x >= 0.575 else 0 for x in df['pred3_probs']]\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix(df['target'], pred3_thr), classes=['0','1'],\n",
    "                        title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также (**Вариант 3**) можно потребовать, чтобы и точность, и полнота были высокими, то есть обе ошибки в матрице ошибок были маленькие. Как вариант - можно минимизировать F1-score (среднее гармоническое между точностью и полнотой).\n",
    "\n",
    "Найдем порог для достижения максимального F1-score для наилучшей модели (вторая модель) и построим матрицу ошибок (***проверьте, что F1-score у двух оставшихся моделей ниже!***)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "for t in np.arange(0.1,1,0.1):\n",
    "    pred1_thr = [1 if x >= t else 0 for x in df['pred1_probs']]\n",
    "    print('threshold =', t)\n",
    "    print('f1-score:', f1_score(df['target'],pred1_thr))\n",
    "    print('accuracy:', accuracy_score(df['target'],pred1_thr))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "for t in np.arange(0.35,0.6,0.025):\n",
    "    pred1_thr = [1 if x >= t else 0 for x in df['pred1_probs']]\n",
    "    print('threshold =', t)\n",
    "    print('f1-score:', f1_score(df['target'],pred1_thr))\n",
    "    print('accuracy:', accuracy_score(df['target'],pred1_thr))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Наилучший результат:***\n",
    "\n",
    "threshold = 0.375\n",
    "\n",
    "f1-score: 0.644\n",
    "    \n",
    "accuracy: 0.65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1_thr = [1 if x >= 0.375 else 0 for x in df['pred1_probs']]\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix(df['target'], pred1_thr), classes=['0','1'],\n",
    "                        title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на roc-auc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print('алгоритм 1:', roc_auc_score(df['target'], df['pred1_probs']))\n",
    "print('алгоритм 2:', roc_auc_score(df['target'], df['pred2_probs']))\n",
    "print('алгоритм 3:', roc_auc_score(df['target'], df['pred3_probs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим roc-кривую для каждой модели и отметим на графике roc-auc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "for n in range(3):\n",
    "    print('Модель ' + str(n+1) + ':')\n",
    "    \n",
    "    fpr, tpr, threshold = roc_curve(df['target'], df['pred' + str(n+1) + '_probs'])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы\n",
    "\n",
    "**1. В данной задаче модель 2 выигрывает по всем метрикам. Однако не во всех задачах одна и та же модель будет лучшей относительно всех метрик!** \n",
    "\n",
    "**2. Качество решения задачи нельзя улучшить с помощью выбора метрики или настройки порога, но с помощью настройки порога можно добиться наилучшего результата в рамках поставленной задачи. Чтобы улучшить качество решения - необходимо изменять саму модель.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Что ещё можно сделать\n",
    "\n",
    "В python есть удобная функция classification_report, которая выводит значения нескольких метрик."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(df['target'],df['pred1_classes']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка качества в задачах многоклассовой классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision, recall & confusion matrix для многоклассовой классификации\n",
    "\n",
    "<img src=\"CM1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"CM2.png\">\n",
    "\n",
    "Для класса Cats:\n",
    "    \n",
    "    precision = доля правильно предсказанных Cats / все предсказанные Cats = 4/13\n",
    "    \n",
    "    recall = доля правильно предсказанных Cats / все истинные Cats = 4/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Constants\n",
    "C=\"Cat\"\n",
    "F=\"Fish\"\n",
    "H=\"Hen\"\n",
    "\n",
    "# True values\n",
    "y_true = [C,C,C,C,C,C, F,F,F,F,F,F,F,F,F,F, H,H,H,H,H,H,H,H,H]\n",
    "# Predicted values\n",
    "y_pred = [C,C,C,C,H,F, C,C,C,C,C,C,H,H,F,F, C,C,C,H,H,H,H,H,H]\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(metrics.confusion_matrix(y_true, y_pred))\n",
    "\n",
    "# Print the precision and recall, among other metrics\n",
    "print(metrics.classification_report(y_true, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Macro avg (average)\n",
    "\n",
    "***macro average (precision) = среднее арифметическое всех (precision)***\n",
    "\n",
    "Пример:\n",
    "***macro avg precision = (0.308+0.667+0.667)/3=0.547***\n",
    "\n",
    "### Micro avg (average)\n",
    "\n",
    "***micro average (precision) = precision, но вычисленная на всех данных вместе.***\n",
    "\n",
    "Пример:\n",
    "precision = TP/(TP+FP)\n",
    "\n",
    "TP - все правильно предсказанные объекты: \n",
    "$$TP = 4 + 2 + 6 = 12$$\n",
    "\n",
    "FP - например, все Cat, предсказанные как Fish и т.д.\n",
    "$$FP = 6 + 3 + 1 + 0 + 1 + 2 = 13$$\n",
    "\n",
    "Поэтому\n",
    "***micro avg precision*** $ = 12/(12+13)=0.480$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cтатьи про метрики качества многоклассовой классификации:\n",
    "    \n",
    "1. https://towardsdatascience.com/multi-class-metrics-made-simple-part-i-precision-and-recall-9250280bddc2\n",
    "        \n",
    "2. https://towardsdatascience.com/multi-class-metrics-made-simple-part-ii-the-f1-score-ebe8b2c2ca1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
